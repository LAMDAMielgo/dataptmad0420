{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "## Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics\n",
    "#### We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now take a look at the shapes of the X and y matricies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X.shape)\n",
    "display(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's pick one entry and see what number is written. Use indexing to pick the 36000th digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4., 149.,\n",
       "       255., 184.,  12.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  11., 133., 212., 253., 253., 253., 102.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 162., 236., 253., 253.,\n",
       "       253., 253., 253.,  55.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        35., 196., 253., 253., 253., 253., 253., 253., 239.,  18.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  89., 249., 253., 253., 253., 185.,\n",
       "       253., 253., 177.,  24.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 129.,\n",
       "       247., 253., 253., 165., 150., 205., 253., 139.,   3.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  89., 247., 253., 240., 131.,  85., 221.,\n",
       "       253., 253.,  84.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4., 187.,\n",
       "       253., 253., 236., 139., 252., 253., 253., 253.,  84.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  21., 253., 253., 253., 253., 253., 253.,\n",
       "       253., 253., 248.,  53.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  99.,\n",
       "       253., 253., 253., 253., 253., 214., 253., 253., 179.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   4., 186., 251., 253., 249., 172.,\n",
       "       133., 253., 253., 137.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  49.,  94.,   6.,   0., 212., 253., 253.,  39.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       126., 253., 253., 197.,   6.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  27., 234., 253., 253.,  94.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       100., 253., 253., 239.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  61., 249., 253., 253.,  79.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   5.,\n",
       "       109., 253., 253., 193.,   4.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  66., 253., 253., 253.,  30.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       147., 253., 253., 182.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  99., 248., 253., 222.,  13.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 36000\n",
    "display(X[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can use the .reshape(28,28) function and plt.imshow() function with the parameters cmap = matplotlib.cm.binary, interpolation=\"nearest\" to make a plot of the number. Be sure to import matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f27248b2dd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_reshape = X.reshape((70000,28,28))\n",
    "\n",
    "plt.imshow(X_reshape[n], cmap = matplotlib.cm.binary, interpolation = 'nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use indexing to see if what the plot shows matches with the outcome of the 36000th index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training, and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) \t (60000,) \t (10000, 784) \t (10000,)\n"
     ]
    }
   ],
   "source": [
    "n = 60000\n",
    "\n",
    "X_train, y_train, X_test, y_test = X[:n], y[:n], X[n:], y[n:]\n",
    "\n",
    "print(f\"{X_train.shape} \\t {y_train.shape} \\t {X_test.shape} \\t {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5421, 784) \t (60000,) \t (892, 784) \t (10000,)\n"
     ]
    }
   ],
   "source": [
    "def filter_array(a):\n",
    "    if a == '5': return True\n",
    "    else: return False\n",
    "    \n",
    "# using broadcasting from numpy to avoid loops\n",
    "vect_filter = np.vectorize(filter_array)\n",
    "tr_bool = vect_filter(y_train).tolist()\n",
    "te_bool = vect_filter(y_test).tolist()\n",
    "\n",
    "# boolean list -> indexing filter\n",
    "X_train_5, y_train_5, X_test_5, y_test_5 = X_train[tr_bool], y_train[tr_bool], X_test[te_bool], y_test[te_bool]\n",
    "print(f\"{X_train_5.shape} \\t {y_train_5.shape} \\t {X_test_5.shape} \\t {y_test_5.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '5', '5', ..., '5', '5', '5'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_train_5) # comprobación, me ha cogido los sólo cincos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets train a logistic regression to predict if a number is a 5 or not (remember to use the 'just 5s' y training set!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/miniconda3/envs/jupyter_env/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# the above division isnt valid --> LR doesnt work with only one cat\n",
    "# Estimator using the default optimizer.\n",
    "\n",
    "estimator = tf.estimator.LinearClassifier(\n",
    "                    feature_columns=[categorical_column_a,\n",
    "                     categorical_feature_a_x_categorical_feature_b])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below, and call it using: never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets fit and predict on the testing set using our never 5 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
